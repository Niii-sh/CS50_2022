# PageRank
    题目链接:https://cs50.harvard.edu/ai/2020/projects/2/pagerank/
    项目的基本背景取自google的页面展示算法 大概就是当我们在搜索引擎中 输入信息进行搜索后 google会展示出网页 而这些网页是按照
    其重要性排序 而这个重要性则取决于网页的质量(这里的质量为其内容 与用户想要搜索内容的关联程度) 
    但是上述对于展示页面的定义是不够完美的 因为网站可以制造许多其他无效页面但内容又和用户想要搜索有着关联(可以理解水内容 只是有关联但没有实质性意义)
    从而会影响网页展示排序的准确性
    所以就有了 PageRank 算法 
     PageRank’s algorithm, a website is more important if it is linked to by other important websites,
    and links from less important websites have their links weighted less.
    实现思路就是 一个网站被越多重要的网站链接则就越重要 而被越多不重要的网站链接则越不重要

## Random Surfer Model
    这个大致思路如下: (推荐去yutube上找个讲解视频看看) :
    每个网页都会与其他网页有链接关系 可以将它们看作有向图 每个节点为一个网页 值表示其被访问的次数(最终转换为概率)
    随机选取一个节点 然后随机按照其边走 每经过一个节点则将其值加1
    在此基础上 由于可能某些节点之间不完全存在联系情况(比如:10个节点 4 3 3分为三个图 三个图之间没有联系)
    则可能出现只在一个图上遍历的情况 所以加入一个系数(damping factor) d 在概率d下 仍然顺着边走(即遍历同一张图) 在1-d的概率下跳到另一张图上遍历节点
    最终根据统计数字转换为概率 将所要展示的页面进行排序 ）

## Iterative Algorithm
    将Random Surfer Model 数学化表示 就是具体转换为具体算法进行实现
    记PR(p) 随机进行random surfer时选择到该页面p的概率
    random sufer选择页面p的方式 有两种:
    1.1-d 概率下 直接随机一个页面
    2.d 概率下根据上一个页面的链接选择下一个页面 即基于上个页面的基础对下个页面进行选择
    第一种情况即为 非条件概率 (1-p)/N (N为总的页面数)
    第二种情况为则需要考虑到前一个页面:
        令NumLinks(i) 表示指向每一个page i的链接数
        而每个页面i 又有其自己的PR(i) 
        故从每个页面i 到其他页面的概率为 PR(i)/NumLinks(i)
    故综上有:
    PR(p) = (1-d)/N + d ∑PR(i)/Numlinks(i) (i取遍所有页面)
    有了上述这些信息就可以进行Markov chanins 的计算过程了 通过公式不断获取hidden state 不断遍历 计算出所有页面的PR(i) 最终排序获得结果
    